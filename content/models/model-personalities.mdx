---
title: "Model Personalities"
description: "Every model has a personality. Gemini plays it safe, GPT balances helpfulness with restraint, Claude pushes boundaries. Knowing their tendencies changes how you prompt."
category: models
order: 5
interactiveTools: [model-picker]
---

Benchmarks tell you what a model *can* do. Personality tells you what it *will* do when you don't spell out every detail. After months of shipping with these models daily, their personalities are as predictable as coworkers.

This matters more than you'd think. Two models with identical benchmark scores can produce wildly different results for the same task — not because one is smarter, but because one interprets ambiguity differently, takes more initiative, or defaults to a different level of caution.

## Gemini: the careful one

Gemini is the model that asks for permission. It's conservative in its interpretations, sticks close to what you asked for, and rarely goes off-script. If you give it an ambiguous task, it's more likely to ask a clarifying question than to make an assumption and run with it.

**Literal-minded.** Gemini does what you say, not what you might have meant. Ask it to "clean up this component" and it'll fix formatting and remove unused imports. It won't restructure the component hierarchy or suggest a different pattern — even when that's what the code actually needs. You have to ask for that explicitly.

**Risk-averse.** When there are multiple valid approaches, Gemini picks the safest one. The most conventional pattern. The approach with the most documentation. This makes it reliable for production work — you rarely get surprised — but it also means you miss out on better solutions that require a judgment call.

**Consistent under pressure.** In long sessions with large contexts, Gemini tends to stay level. It doesn't drift as much as other models. It doesn't suddenly get "creative" with your architecture at the end of a long conversation. For marathon refactoring sessions, this steadiness is worth a lot.

**Where it falls short.** If you need the model to push back on your approach, suggest alternatives, or notice that you're solving the wrong problem — Gemini usually won't. It's a reliable executor, not a thought partner.

## GPT / Codex: the balanced one

GPT (and by extension Codex) sits in the middle. It takes initiative when the situation is clear, defers when it's ambiguous, and generally produces output that feels "sensible" without being surprising. It's the colleague who does solid work and rarely makes you nervous.

**Pragmatic defaults.** GPT tends to pick the approach that most developers would pick. It reads like Stack Overflow's accepted answer — not the most clever solution, but the one that works and that other developers will understand. For team codebases, this is often exactly what you want.

**Measured initiative.** It'll fill in reasonable gaps without asking — default error handling, obvious edge cases, standard patterns — but it stops short of making architectural decisions. It adds the null check but doesn't restructure your data flow. This hit rate of "helpful without overstepping" is high.

**Good at reading the room.** If your prompt is detailed and specific, GPT stays precise. If your prompt is loose, it makes reasonable assumptions but flags them. It adapts its level of initiative to match your level of specificity, which is a surprisingly useful trait.

**Predictable in output format.** GPT is the most consistent at following output format instructions. If you say "respond in JSON" or "only output the code, no explanation", it almost always complies. Other models sometimes can't help themselves and add commentary anyway.

**Where it falls short.** GPT rarely surprises you with insight. It won't say "actually, you should do this differently" unless you specifically ask for a review. It optimizes for giving you what you asked for, not for giving you what you need.

## Claude Sonnet: the proactive one

Claude has opinions, and it's not shy about sharing them. It's the model most likely to push back on your approach, suggest an alternative, notice a bug you didn't ask about, or restructure your code to be "better" — even when you just wanted a simple change.

**Genuinely creative.** Ask Claude to implement a feature and it might suggest a better API surface, point out that your data model will cause problems at scale, or restructure the code in a way you hadn't considered. When it's right — which is often — this is the most valuable thing a model can do. It's a real thought partner.

**Proactive to a fault.** Claude notices things. While implementing a feature, it'll spot an inconsistent naming convention across files, a missing error boundary, a potential race condition in adjacent code. It'll mention these, and it'll often fix them without being asked. In a short session this feels magical. In a long session it's how you end up reviewing a 40-file diff when you asked for a 3-file change.

**Opinionated about code quality.** Claude has strong preferences about code structure, naming, and patterns. It will refactor code to match its taste. Sometimes its taste is better than yours. Sometimes it's just different, and now you're spending time reviewing changes you didn't want. Setting explicit constraints ("do not refactor unless I ask") is essential.

**Excellent at explaining.** When you need to understand something — why code is broken, how a library works, what tradeoff you're making — Claude gives the clearest, most useful explanations. It connects the dots between your specific code and the general principle. This is where the "personality" really shines.

**Where it falls short.** Scope creep. Claude's instinct to be helpful means it expands tasks in ways that feel reasonable in the moment but make output harder to review. The fix is explicit scope constraints in your prompt or `CLAUDE.md`.

## Claude Opus: the deep thinker

Opus is Claude dialed up. Everything that makes Sonnet distinctive — the creativity, the proactiveness, the opinions — Opus has more of. But it adds something Sonnet doesn't quite match: depth. Opus doesn't just notice things; it understands them in context.

**Deep accuracy.** Where other models pattern-match, Opus traces the actual logic. It catches bugs that require understanding three levels of indirection. It identifies race conditions by mentally simulating concurrent execution. It spots type issues that TypeScript itself misses. This isn't just "smarter" — it's a qualitatively different way of engaging with code.

**Architecturally creative.** Opus doesn't just suggest a different function name — it might suggest a different abstraction entirely, and explain why your current approach will create problems two features from now. It thinks in systems, not just in code. When you're making design decisions that will compound, this perspective is worth the cost.

**Thorough to the point of slow.** Opus takes its time. It considers more options, explores more edge cases, and gives more complete answers. For quick tasks this is overkill — you're paying for depth you don't need. For hard problems, architecture decisions, and debugging subtle issues, the thoroughness pays for itself many times over.

**Proactive with substance.** Where Sonnet might fix a naming inconsistency, Opus will notice that your abstraction is leaking, explain why, and suggest a restructure that fixes the root cause. Its unsolicited observations tend to be higher signal.

**Where it falls short.** Cost and latency. Opus is expensive and slow compared to Sonnet. For routine tasks — scaffolding, simple refactors, boilerplate — you're burning money without getting proportional value. Reserve it for the problems that actually need it.

## How personality affects prompting

Knowing these personalities changes how you prompt:

**For Gemini:** be explicit about what you want. If you want alternatives, ask for them. If you want it to push back on your approach, say so. Don't expect it to read between the lines.

**For GPT:** give it clear specs and let it work. It'll fill in reasonable defaults. Be specific about output format and constraints — it's excellent at following them.

**For Claude Sonnet:** set boundaries. "Only modify the files I specify." "If you notice something outside this task, mention it but don't fix it." Then let its creativity work within those boundaries.

**For Claude Opus:** use it for the hard problems. Architecture reviews, complex debugging, design decisions with long-term implications. Pair it with explicit scope constraints to keep the depth focused where you need it.

The right model isn't just the smartest one — it's the one whose personality matches the task. A careful model for production refactors. A creative model for design exploration. A balanced model for everyday shipping.

<ModelPicker />
