---
title: "Coding: Refactor vs Greenfield"
description: "Different model needs for refactoring existing code vs writing from scratch. Greenfield is easier than it looks; refactoring is harder."
category: models
order: 2
interactiveTools: [model-picker, cost-calculator]
---

Greenfield and refactoring feel like the same job — writing code — but they're completely different tasks for an AI model. Greenfield is mostly a generation problem. Refactoring is a comprehension problem first, then a generation problem. That distinction changes which model you want.

When I'm starting a new component, a new API route, or a new utility from scratch, I can give the model a clear spec and it can generate something reasonable without deep context. The output quality depends mostly on how well I describe what I want.

Refactoring is different. The model needs to understand *what the existing code is doing*, *why it's structured that way*, and *what can and can't change*. That's a much harder task, and it's where I've seen the most failures.

## The refactoring failure mode

The most common refactoring failure I've hit: the model "understands" the code well enough to make changes that look correct but subtly break behavior. It renames a variable that was intentionally named that way for a reason. It extracts a function but changes the execution order. It simplifies a condition that was handling an edge case.

These bugs are hard to catch because the code looks cleaner after the refactor. The model is confidently wrong.

The fix: be extremely explicit about constraints. "Do not change the public API", "do not modify the test files", "do not change the execution order of these operations". The more constraints you give, the less room there is for creative interpretation.

## Greenfield: the model matters less than the spec

For greenfield work, I've found that the quality of my spec matters more than the model I use. A well-specified task with clear inputs, outputs, and constraints will produce good results from Sonnet or even Haiku. A vague task will produce mediocre results from any model.

The exception: when the greenfield task involves non-obvious architectural decisions. "Build a caching layer for this API" has many valid implementations with different tradeoffs. That's where a reasoning model earns its cost — it can evaluate the options against your constraints rather than just picking the most common pattern.

## Model recommendations by task type

<ModelPicker />

## Cost comparison: refactor vs greenfield

Refactoring tasks tend to use more input tokens (you're sending existing code as context) and produce fewer output tokens. Greenfield is the opposite. This affects the cost calculation significantly.

<CostCalculator />
